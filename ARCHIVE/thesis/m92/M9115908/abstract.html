<html>
<head>
<title> 科技大學智慧型系統實驗室 研究論文 NTUST Fuzzy Neural Lab Paper </title>
<meta http-equiv="Content-Type" content="text/html; charset=big5">
</head>

<BODY background="/picture/background/gray_roc.gif" bgcolor="#ffffff" text="#000000" link="#55ffff" vlink="#6966ff">
<img align=left src="/picture/logo/logo.gif"> <strong> <font size=5>國立台灣科技大學 資訊工程系所</font><br>
<font size="6">智慧型系統實驗室 研究論文</font><br>
<font size=4>Intelligent System Laboratory Paper</font> </strong> 
<hr size=10>
<h1>94級畢業碩士 游清圳 發表論文</h1>
<hr size=5>
<center>
  <table width=80%>
    <tr>
      <td> 
        <center>
		<h3><a name="AIC">網路主題模型: 以關聯資料為基礎的特徵翠取法</a></h3>
        </center>
        <h4>摘要</h4>
        <p align="JUSTIFY">
  &nbsp;&nbsp;&nbsp;&nbsp;統計關聯學習是一種新興的機械學習研究。它是一種將統計學習結合關聯表示的方法，用來解決關聯資料的預測問題。統計關聯學習主要的研究方向為關聯表示語言及結合關聯表示語言用來萃取特徵，再將這些特徵運用到機械學習的方法。在統計關聯學習的研究中，大部分的研究是使用歸納邏輯級程式設計及或然關聯模型來萃取特徵。但由於歸納邏輯級程式設計的特徵只提供單一資訊，而或然關聯模型只使用分佈機率，因此遺漏彼此的資訊以至於在分類時降低了預測的準確率。為此，我們提議將這兩種資訊整合在一起作為預測學習的知識表示法，用來改善預測的準確度。為此，我們提議網路主題模型的理論來萃取關聯資料的特徵。因為我們是用網路主題(network motifs)來萃取關聯資料的交互連結圖形，因此我們稱這種方法為網路主題模型。而藉由網路主題模型可以確實從關聯資料中萃取出有意義的特徵。我們將這些特徵運用到分類問題。而實驗的結果顯示出這些特徵是非常有意義的，且確實的改善了分類的準確度。這結果顯示網路主題模型是一個好的特徵萃取模型。
        </p>
     </td>
    </tr>
  </table>
  <hr>
  <table width=80%>
    <tr>
      <td> 
        <center>
		<h3><a name="AIE">Network Motif Model: An Efficient Approach to Extract Features from Relational Data</a></h3>
        </center>
	<h4>Abstract</h4>
	<p align="JUSTIFY">&nbsp;&nbsp;&nbsp;&nbsp;Statistical relational learning is an emerging research area in machine learning that combines statistical learning with relational representations to predict properties of relational data. Some learning models are frequently used to solve feature extraction of relational data in statistical relational learning research area.  These models include first-order Bayesian classifier (1BC2) [Fla04], probabilistic relational models (PRMs) [Get03c], and relational Markov networks (RMNs) [Fri04].  They are based on inductive logic programming and Bayesian network [Dze01][Nev03a].<BR>
		&nbsp;&nbsp;&nbsp;&nbsp;Inductive logic programming (ILP) [Nug94] is deterministic classification approaches, which uses inductive methods to extract features.  Nevertheless, inductive logic programming does not model probability distribution; therefore, due to the particular predicate adopted by these approaches [Dze01].  Because of this, Lise Getoor et al. [Get03c] proposed a probability relational model (PRMs), which uses probability distribution to predict the properties of objects.<BR>
		&nbsp;&nbsp;&nbsp;&nbsp;Probability relational models integrate probability models and relational logic.  It is found that using these two approaches (ILP and PRMs) to extract features cannot achieve high performance, especially extracting features from multi-relational data.  This is because ILP uses first-order logic to represent data, but it extracts single property features only [Fla04]; thus, we cannot obtain multiple label features using ILP.  PRMs use probability distribution to predict properties of objects, but the feature is described by a value of probability distribution; thus, PRMs cannot integrate first-order information into the feature.  Therefore, in statistical relational learning, current feature extraction approaches cannot achieve high accuracy in predicting properties of objects<BR>
		&nbsp;&nbsp;&nbsp;&nbsp;Using PRMS to extract features, the first step is to discover sub-graphs.  Then, the probability distributions of the sub-graphs will be calculated.  Please notice that the probability distribution of this sub-graph is a feature.  Hence, after computation, many probabilities distributions of sub-graphs will generate many features.  Next, these features will be applied to Bayesian network to predict the properties of objects.<BR>
		&nbsp;&nbsp;&nbsp;&nbsp;It is found that these sub-graphs can be multiple label features, yet the significances of sub-graphs are not clear enough.  On the other hand, network motifs can identify significant sub-graphs from network structure in complex networks.  Compared with sub-graphs identified by PRMs, using network motifs to predict sub-graphs can identify far more sub-graphs than PRMs.  If the sub-graphs of network motifs can be combined with first-order information, the significancy of sub-graphs will be clearer.<BR>
		&nbsp;&nbsp;&nbsp;&nbsp;We assume that using sub-graphs as multiple label features might describe the properties of objects clearer; the accuracy in predicting properties of objects might be improved.  Therefore, this thesis will focus on extracting multiple label features by network motifs to improve the accuracy in predicting properties of objects in order to prove our assumption is correct.  Experiment results clearly show that network motif model is a good feature extraction in statistical relational learning.<BR>
     </td>
    </tr>
  </table>

  <br>
</center>
<hr size=6>
<center>
  <a href=/index.html><img border=0 src=/picture/icons/home.gif></a> <a href="mailto:WWW@neuron.et.ntust.edu.tw"> 
  <img border=0 src=/picture/icons/email.gif></a> 
</center>
</body>
</html>